AutoGen-Powered Multi-Agent System
==================================

This project leverages Microsoft's AutoGen framework to create a collaborative multi-agent system capable of solving complex tasks, such as code generation, data analysis, and automated problem-solving. By simulating a team of specialized AI agents, the system can autonomously plan, execute, and validate tasks with minimal human intervention.

Overview
--------

AutoGen is a framework for simplifying the orchestration, optimization, and automation of complex LLM workflows. This project demonstrates a practical implementation of AutoGen where multiple agents, each with a specific role, collaborate in a group chat to achieve a user-defined objective. The system typically includes a coder, a reviewer, and a proxy for the user that executes code and provides feedback.

Key Features
------------

*   **Multi-Agent Collaboration:** Employs a team of agents (e.g., Engineer, Critic, Executor) that converse to solve problems.
    
*   **Automated Workflow:** Agents can autonomously decompose tasks, write code, review it for errors, and execute it.
    
*   **Code Generation & Execution:** Capable of writing and running Python scripts in a sandboxed environment to perform tasks.
    
*   **Human-in-the-Loop:** Allows for a human user to provide input, give feedback, and guide the agents' conversation.
    
*   **Customizable Personas:** Agent roles and capabilities are defined by clear, customizable system prompts.
    

How It Works: The AutoGen Architecture
--------------------------------------

The system is built around a "Group Chat" paradigm where agents interact to complete a task given by the user.

1.  **Initialization:** The user provides an initial task or problem statement.
    
2.  **User Proxy Agent:** This agent acts on behalf of the human user. It's responsible for initiating the task and, crucially, executing any code written by other agents. It can be configured to require human approval before execution.
    
3.  **Engineer/Coder Agent:** This is the primary problem-solving agent. It receives the task and writes the necessary Python code to solve it.
    
4.  **Critic/Reviewer Agent:** This agent's role is to review the code generated by the Engineer. It checks for bugs, suggests improvements, and ensures the code adheres to best practices.
    
5.  **Group Chat Manager:** This component orchestrates the conversation between the agents, managing the turn-taking and ensuring the workflow proceeds logically.
    

The typical conversation flow is as follows:

1.  The User Proxy introduces the task to the group.
    
2.  The Engineer writes a piece of code and presents it.
    
3.  The Critic reviews the code and provides feedback.
    
4.  The Engineer revises the code based on the feedback.
    
5.  This loop continues until the code is approved.
    
6.  The User Proxy executes the final code and reports the result, concluding the task.
    

### Technology Stack

*   **Language:** Python 3.x
    
*   **Core Framework:** Microsoft AutoGen (pyautogen)
    
*   **LLM:** Configured to use OpenAI models (e.g., GPT-4) but can be adapted for others.
    

Setup and Installation
----------------------

Follow these steps to set up and run the project locally.

### 1\. Prerequisites

*   Python 3.8 or higher
    
*   An OpenAI API Key (or access to another LLM endpoint)
    

### 2\. Clone the Repository

```Bash 
git clone [https://github.com/abhijit-d01/AI-Agents.git](https://github.com/abhijit-d01/AI-Agents.git)
cd AI-Agents/AutoGen
```
### 3\. Create a Virtual Environment

Shell python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`

### 4\. Install Dependencies

```Bash
pip install -r requirements.txt
```

### 5\. Configure LLM Provider

AutoGen requires a configuration file to know which LLM to use. Create a file named OAI\_CONFIG\_LIST.json in the project's root directory and populate it with your model details.

**Example OAI\_CONFIG\_LIST.json:**

```Bash 
[
    {
        "model": "gpt-4",
        "api_key": "your-openai-api-key"
    }
]
```

Usage
-----

Run the main application from the terminal. The script will prompt you to enter a task for the agents to solve.

Shell python main.py

The agents will then begin their collaborative conversation, which will be printed to the console. To exit the application, type exit main.

Pro point. It initializes the agents and the group chat, and starts the workflow.
---------------------------------------------------------------------------------

1.  **agents.py** (optional but recommended): Contains the configuration and system prompts for the different agents.
    
2.  **OAI\_CONFIG\_LIST.json**: The required configuration file for your LLM endpoint(s).itions for the custom tools that the assistant can use.
    
3.  **requirements.txt**: A list of all Python dependencies.
    

Example
-------

```Bash 
$ python main.py
> Starting AI Assistant... Type 'exit' to quit.
You: What was the score of the latest world cup final and who scored the goals?

> Assistant is thinking... (Calling Agent -> Using Tool: tavily_search_results_json)

Assistant: The final of the 2022 FIFA World Cup between Argentina and France ended in a 3-3 draw after extra time. Argentina won the subsequent penalty shootout 4-2.

The goal scorers were:
- **Argentina:** Lionel Messi (2 goals), Ángel Di María (1 goal).
- **France:** Kylian Mbappé (3 goals - a hat-trick).
```